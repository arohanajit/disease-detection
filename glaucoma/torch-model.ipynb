{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled12.ipynb",
      "provenance": [],
      "private_outputs": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arohanajit/disease-detector/blob/master/glaucoma/torch-model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m2hPIyVWYDiV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchsummary import summary\n",
        "from torch import optim\n",
        "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "from torchvision.datasets import ImageFolder\n",
        "import torchvision.transforms as transforms\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "from tqdm import tqdm_notebook\n",
        "import shutil\n",
        "train_on_gpu = torch.cuda.is_available()\n",
        "print(train_on_gpu)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4elDp1mXYFnn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "if 'loader.py' not in os.listdir():\n",
        "    !wget https://raw.githubusercontent.com/arohanajit/disease-detector/master/loader.py\n",
        "import loader\n",
        "if 'data' not in os.listdir():\n",
        "    loader.load_data()\n",
        "    !kaggle datasets download -d himanshuagarwal1998/glaucomadataset\n",
        "    !unzip glaucomadataset.zip\n",
        "    !mkdir data\n",
        "    !mv Glaucoma data/Glaucoma\n",
        "    !mv \"Non Glaucoma\" data/\"Non Glaucoma\" \n",
        "    !rm glaucomadataset.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AFkEWFGUYZbR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_transforms = transforms.Compose([\n",
        "    transforms.Resize((224,224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                        std=[0.229, 0.224, 0.225])\n",
        "    ])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mluB0bMsZXsq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = ImageFolder('data/',transform=data_transforms)\n",
        "valid_size = 0.15\n",
        "test_size = 0.15\n",
        "print(len(data))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uXa15TpiZfz6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_train = len(data)\n",
        "indices = list(range(num_train))\n",
        "np.random.shuffle(indices)\n",
        "valid_split = int(np.floor((valid_size) * num_train))\n",
        "test_split = int(np.floor((valid_size+test_size) * num_train))\n",
        "valid_idx, test_idx, train_idx = indices[:valid_split], indices[valid_split:test_split], indices[test_split:]\n",
        "\n",
        "print(len(valid_idx), len(test_idx), len(train_idx))\n",
        "\n",
        "# define samplers for obtaining training and validation batches\n",
        "train_sampler = SubsetRandomSampler(train_idx)\n",
        "valid_sampler = SubsetRandomSampler(valid_idx)\n",
        "test_sampler = SubsetRandomSampler(test_idx)\n",
        "\n",
        "\n",
        "loaders = {\n",
        "    'train': torch.utils.data.DataLoader(data, batch_size=20, sampler=train_sampler),\n",
        "    'test': torch.utils.data.DataLoader(data, batch_size=10, sampler=test_sampler),\n",
        "    'valid': torch.utils.data.DataLoader(data, batch_size=10, sampler=valid_sampler),\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FqyVQMLKaz5t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "class_labels = ['Non Glaucoma','Glaucoma']\n",
        "def imshow(img):\n",
        "    img = img / 2 + 0.5  \n",
        "    plt.imshow(np.transpose(img, (1, 2, 0)))\n",
        "\n",
        "dataiter = iter(loaders['train'])\n",
        "images, labels = dataiter.next()\n",
        "print(images.shape,labels.shape)\n",
        "images = images.numpy() \n",
        "fig = plt.figure(figsize=(25, 16))\n",
        "\n",
        "for idx in np.arange(20):\n",
        "    ax = fig.add_subplot(4, 10/2, idx+1, xticks=[], yticks=[])\n",
        "    imshow(images[idx])\n",
        "    ax.set_title(class_labels[int(labels[idx])],fontsize=20,color='white')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mWeS25qbbAMM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torchvision.models as models\n",
        "model = models.densenet121(pretrained=True)\n",
        "for params in model.features.parameters():\n",
        "    params.requires_grad = False\n",
        "model.classifier = nn.Sequential(\n",
        "    nn.Linear(1024,1024,bias=True),\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(0.2),\n",
        "    nn.Linear(1024,2,bias=True)\n",
        ")\n",
        "print(model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qCFirIYl0GhI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hpw3LVR01UNq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Graphing(train,test):\n",
        "    plt.plot(train)\n",
        "    plt.plot(test)\n",
        "    plt.legend(['Train Loss','Validation Loss'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E1nO9H0l1V7F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from PIL import ImageFile\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "def train(n_epochs, loaders, model, optimizer, criterion, train_on_gpu, save_path):\n",
        "    \"\"\"returns trained model\"\"\"\n",
        "    # initialize tracker for minimum validation loss\n",
        "    valid_loss_min = np.Inf \n",
        "    train = []\n",
        "    test = []\n",
        "    for epoch in tqdm(range(1, n_epochs+1)):\n",
        "        # initialize variables to monitor training and validation loss\n",
        "        train_loss = 0.0\n",
        "        valid_loss = 0.0\n",
        "        valid_min = 9999\n",
        "        train_total = 0\n",
        "        val_total = 0\n",
        "        train_correct = 0\n",
        "        val_correct = 0\n",
        "        ###################\n",
        "        # train the model #\n",
        "        ###################\n",
        "        model.train()\n",
        "        for batch_idx, (data, target) in enumerate(loaders['train']):\n",
        "            # move to GPU\n",
        "            if train_on_gpu:\n",
        "                data, target = data.cuda(), target.cuda()\n",
        "            ## find the loss and update the model parameters accordingly\n",
        "            ## record the average training loss, using something like\n",
        "            ## train_loss = train_loss + ((1 / (batch_idx + 1)) * (loss.data - train_loss))\n",
        "            optimizer.zero_grad()\n",
        "            out = model(data)\n",
        "            loss = criterion(out,target)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_loss = train_loss + ((1 / (batch_idx + 1)) * (loss.data - train_loss))\n",
        "            if batch_idx%20==0:\n",
        "                print('Batch: {}\\tEpoch: {} \\tTraining Loss: {:.6f}'.format(\n",
        "                batch_idx,\n",
        "                epoch, \n",
        "                train_loss\n",
        "                ))\n",
        "\n",
        "\n",
        "\n",
        "        ######################    \n",
        "        # validate the model #\n",
        "        ######################\n",
        "        model.eval()\n",
        "        for batch_idx, (data, target) in enumerate(loaders['valid']):\n",
        "            # move to GPU\n",
        "            if train_on_gpu:\n",
        "                data, target = data.cuda(), target.cuda()\n",
        "            output = model(data)\n",
        "            loss = criterion(output,target)\n",
        "            valid_loss = valid_loss + ((1 / (batch_idx + 1)) * (loss.data - valid_loss))\n",
        "            ## update the average validation loss\n",
        "\n",
        "            \n",
        "        train.append(train_loss)\n",
        "        test.append (valid_loss)\n",
        "        # print training/validation statistics \n",
        "        print('Epoch: {} Training Loss: {:.6f} Validation Loss: {:.6f}'.format(\n",
        "            epoch, \n",
        "            train_loss,\n",
        "            valid_loss,\n",
        "            ))\n",
        "        if valid_loss <= valid_loss_min:\n",
        "            print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
        "            valid_loss_min,\n",
        "            valid_loss))\n",
        "            torch.save(model.state_dict(), save_path)\n",
        "            valid_loss_min = valid_loss\n",
        "        \n",
        "        \n",
        "            \n",
        "    # return trained model\n",
        "    Graphing(train,test)\n",
        "    return model\n",
        "\n",
        "\n",
        "# train the model\n",
        "train(10, loaders, model, optimizer, criterion, train_on_gpu, 'model.pt')\n",
        "\n",
        "# load the model that got the best validation accuracy\n",
        "model.load_state_dict(torch.load('model.pt'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R28s09Ox1g2J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test(loaders, model, criterion, use_cuda):\n",
        "\n",
        "    # monitor test loss and accuracy\n",
        "    test_loss = 0.\n",
        "    correct = 0\n",
        "    total = 0.\n",
        "\n",
        "    model.eval()\n",
        "    for batch_idx, (data, target) in enumerate(loaders['test']):\n",
        "        # move to GPU\n",
        "        if use_cuda:\n",
        "            data, target = data.cuda(), target.cuda()\n",
        "        # forward pass: compute predicted outputs by passing inputs to the model\n",
        "        output = model(data)\n",
        "        # calculate the loss\n",
        "        loss = criterion(output, target)\n",
        "        # update average test loss \n",
        "        test_loss = test_loss + ((1 / (batch_idx + 1)) * (loss.data - test_loss))\n",
        "        # convert output probabilities to predicted class\n",
        "        pred = output.data.max(1, keepdim=True)[1]\n",
        "        # compare predictions to true label\n",
        "        correct += np.sum(np.squeeze(pred.eq(target.data.view_as(pred))).cpu().numpy())\n",
        "        total += data.size(0)\n",
        "            \n",
        "    print('Test Loss: {:.6f}\\n'.format(test_loss))\n",
        "\n",
        "    print('\\nTest Accuracy: %2d%% (%2d/%2d)' % (\n",
        "        100. * correct / total, correct, total))\n",
        "\n",
        "# call test function    \n",
        "test(loaders, model, criterion, train_on_gpu)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gNml-VRX1kna",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}